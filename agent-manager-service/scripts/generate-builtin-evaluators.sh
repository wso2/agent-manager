#!/bin/bash
# ============================================================================
# Generate Builtin Evaluators Go Catalog
# ============================================================================
# This script generates catalog/builtin_evaluators.go from the amp-evaluation
# library. The generated Go file is compiled directly into the service binary —
# no database or JSON file is needed at runtime.
#
# Usage:
#   ./generate-builtin-evaluators.sh [options]
#
# Options:
#   --amp-eval-version  Version of amp-evaluation to install from PyPI (default: latest)
#   --output            Output file path (default: ./catalog/builtin_evaluators.go)
#   --dev               Use local source from libs/amp-evaluation (for development)
#
# Examples:
#   # Development (uses local source)
#   ./generate-builtin-evaluators.sh --dev
#
#   # Production (installs from PyPI)
#   ./generate-builtin-evaluators.sh --amp-eval-version 0.1.0
# ============================================================================

set -euo pipefail

# Default configuration
AMP_EVAL_VERSION="${AMP_EVAL_VERSION:-}"
OUTPUT_FILE="${OUTPUT_FILE:-./catalog/builtin_evaluators.go}"
DEV_MODE=false

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --amp-eval-version)
            AMP_EVAL_VERSION="$2"
            shift 2
            ;;
        --output)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        --dev)
            DEV_MODE=true
            shift
            ;;
        *)
            echo "Unknown option: $1"
            exit 1
            ;;
    esac
done

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
NC='\033[0m'

log_info() {
    echo -e "${NC}ℹ️  $1${NC}"
}

log_success() {
    echo -e "${GREEN}✓ $1${NC}"
}

log_error() {
    echo -e "${RED}✗ $1${NC}"
}

# Check for Python
if ! command -v python3 &> /dev/null; then
    log_error "python3 is required but not installed"
    exit 1
fi

log_info "Generating builtin evaluators Go catalog..."

# Create output directory if needed
OUTPUT_DIR=$(dirname "${OUTPUT_FILE}")
mkdir -p "${OUTPUT_DIR}"

# Create temporary virtual environment
VENV_DIR=$(mktemp -d)/venv
trap 'deactivate 2>/dev/null || true; rm -rf "$(dirname "${VENV_DIR}")"' EXIT

python3 -m venv "${VENV_DIR}"
source "${VENV_DIR}/bin/activate"

pip install --quiet --upgrade pip

if [[ "${DEV_MODE}" == "true" ]]; then
    # Development mode: use local source
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    LOCAL_AMP_EVAL="${SCRIPT_DIR}/../../libs/amp-evaluation"

    if [[ -d "${LOCAL_AMP_EVAL}" ]]; then
        log_info "Installing amp-evaluation from local source (dev mode)..."
        pip install --quiet -e "${LOCAL_AMP_EVAL}"
    else
        log_error "Local amp-evaluation not found at ${LOCAL_AMP_EVAL}"
        log_error "Run from repository root or use --amp-eval-version for production"
        exit 1
    fi
elif [[ -n "${AMP_EVAL_VERSION}" ]]; then
    log_info "Installing amp-evaluation==${AMP_EVAL_VERSION} from PyPI..."
    pip install --quiet "amp-evaluation==${AMP_EVAL_VERSION}"
else
    log_info "Installing latest amp-evaluation from PyPI..."
    pip install --quiet amp-evaluation
fi

# Generate the Go source file
python3 << 'PYTHON_SCRIPT' > "${OUTPUT_FILE}"
import json
import sys
from amp_evaluation.evaluators.builtin import list_builtin_evaluators

evaluators = list_builtin_evaluators()

def to_display_name(identifier):
    """Derive a human-readable display name from an evaluator identifier."""
    # Take the part after the last "/" for namespaced identifiers
    base = identifier.split("/")[-1]
    return base.replace("_", " ").replace("-", " ").title()

def go_value(v):
    """Format a Python value as a Go literal for the interface{} Default field."""
    if v is None:
        return "nil"
    elif isinstance(v, bool):
        return "true" if v else "false"
    elif isinstance(v, int):
        return f"float64({v})"
    elif isinstance(v, float):
        # Format without trailing zeros but keep precision
        formatted = f"{v}"
        return f"float64({formatted})"
    elif isinstance(v, str):
        return json.dumps(v)  # adds quotes and escapes special chars
    elif isinstance(v, list):
        items = ", ".join(json.dumps(item) if isinstance(item, str) else go_value(item) for item in v)
        return f"[]interface{{}}{{{items}}}"
    else:
        return "nil"

def go_strings(lst):
    """Format a list of strings as a Go []string literal."""
    if not lst:
        return "nil"
    items = ", ".join(json.dumps(s) for s in lst)
    return f"[]string{{{items}}}"

def go_float_ptr(v):
    """Format a float as floatPtr(v)."""
    if v is None:
        return ""
    formatted = f"{v}"
    return f"floatPtr({formatted})"

lines = [
    "// Code generated by scripts/generate-builtin-evaluators.sh; DO NOT EDIT.",
    "",
    "package catalog",
    "",
    'import "github.com/wso2/ai-agent-management-platform/agent-manager-service/models"',
    "",
    "var entries = []*Entry{",
]

for ev in evaluators:
    identifier = ev["name"]
    display_name = to_display_name(identifier)
    description = ev.get("description", "")
    version = ev.get("version", "1.0")
    provider = ev.get("metadata", {}).get("module", "")
    class_name = ev.get("metadata", {}).get("class_name", "")
    tags = ev.get("tags", [])
    config_schema = ev.get("config_schema", [])

    lines.append("\t{")
    lines.append(f"\t\tIdentifier:  {json.dumps(identifier)},")
    lines.append(f"\t\tDisplayName: {json.dumps(display_name)},")
    lines.append(f"\t\tDescription: {json.dumps(description)},")
    lines.append(f"\t\tVersion:     {json.dumps(version)},")
    lines.append(f"\t\tProvider:    {json.dumps(provider)},")
    lines.append(f"\t\tClassName:   {json.dumps(class_name)},")
    lines.append(f"\t\tTags:        {go_strings(tags)},")

    if config_schema:
        lines.append("\t\tConfigSchema: []models.EvaluatorConfigParam{")
        for param in config_schema:
            key = param.get("key", "")
            ptype = param.get("type", "string")
            desc = param.get("description", "")
            required = "true" if param.get("required", False) else "false"
            default_val = go_value(param.get("default", None))
            min_val = param.get("min", None)
            max_val = param.get("max", None)
            enum_values = param.get("enum_values", [])

            field_parts = [
                f"Key: {json.dumps(key)}",
                f"Type: {json.dumps(ptype)}",
                f"Description: {json.dumps(desc)}",
                f"Required: {required}",
            ]
            if default_val != "nil":
                field_parts.append(f"Default: {default_val}")
            else:
                field_parts.append("Default: nil")
            if min_val is not None:
                field_parts.append(f"Min: {go_float_ptr(min_val)}")
            if max_val is not None:
                field_parts.append(f"Max: {go_float_ptr(max_val)}")
            if enum_values:
                field_parts.append(f"EnumValues: {go_strings(enum_values)}")

            lines.append("\t\t\t{" + ", ".join(field_parts) + "},")
        lines.append("\t\t},")
    else:
        lines.append("\t\tConfigSchema: []models.EvaluatorConfigParam{},")

    lines.append("\t},")

lines.append("}")
print("\n".join(lines))
PYTHON_SCRIPT

EVALUATOR_COUNT=$(python3 -c "
import sys
sys.path.insert(0, '${VENV_DIR}/lib/python3.*/site-packages' if False else '.')
count = 0
with open('${OUTPUT_FILE}') as f:
    for line in f:
        if line.strip().startswith('Identifier:'):
            count += 1
print(count)
")

log_success "Generated ${EVALUATOR_COUNT} evaluators to ${OUTPUT_FILE}"
